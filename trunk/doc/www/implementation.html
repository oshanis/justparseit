<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-2" />
<title>6.863 Project: Policy Parser</title>
<link rel="stylesheet" type="text/css" href="style.css" />
</head>
<body>

	<!-- Begin Wrapper -->
	
		<div id="wrapper">
		
		<!-- Begin Header -->
			
			<div id="header">
				<h1>Policy Parser</h1>
				<h2>6.863 Spring 2008 Project</h2>		 
			</div>
			
		<!-- End Header -->
			
		<!-- Begin Strap -->
		
        <div id="strap">
<b>Policy Parser</b> &raquo; Implementation</div>
		
		<!-- End Strap -->
		 
		<!-- Begin Navigation -->
		
		<div id="navigation">
			<ul id="menu">
				<li><a href="index.html">Home</a></li>
				<li><a href="intro.html">Intro</a></li>
			    <li><a href="try.html">Try It Now!</a></li>
	            <li><a href="#">Implementation</a></li>
                <li><a href="results.html">Results</a></li>
	            <li><a href="future.html">Future Directions</a></li>
	            <li><a href="download.html">Download Code</a></li>
 			 	<li><a href="members.html">Members</a></li>
			</ul>
		</div>
		
		<!-- End Navigation -->
		 
		<!-- Begin Content-->

		<div id="content">
		    <h2> Implementation of the Policy Parser</h2>
			<br />
			<p> As briefly described in
			the <a href="intro.html">Intro</a> section, the Policy
              Parser consists of three major components: the NLTK
			  Parser, the Policy Interpreter, and the RDF
			  Generator.  The system also
			  includes the online RDF policy store as well as the AIR
			  reasoner, but these can be considered peripheral to the
			  above three components.  In this section, we will describe each
			  of these components in detail. Before we dive
			  into the detail, we first define the scope
			  of our project with respect to the types of user input that
			  the Policy Parser is capable of handling.
            </p><br />
            <p><b>Assumptions on User Input</b>:</p><br />
            <p>Automatically parsing <i>any</i> natural
              language sentence is an extremely challenging task, and
              is out of scope of this project. Thus, we focus on a set
              of <i>constrained</i> natural language sentences; more
              specfiically, our system is able to accept a sentence
              of the following form:
            </p><br />
            <p>
              <tt>subject [mod] action object ['to' secondary_object] 
                ['for' purpose] [condition]*</tt>
            </p><br /> 
            <p>
              where the meanings of the constituents are the following:
              <ul id="panel">
                <li> <tt>subject</tt>: The main actor or entity who
                carries out an action (e.g. "A student")
                <li> <tt>mod</tt>: An optional modality for an action
                (e.g. "can" or "cannot")
                <li> <tt>action</tt>: The action performed by the
                subject (e.g "transfer")
                <li> <tt>object</tt>: The object on which the action
                is performed (e.g. "a proximity card")
                <li> <tt>secondary object</tt>: an optional object
                that modifies the action (e.g. "to another person") 
                <li> <tt>purpose</tt>: an optional purpose for which the
                action is performed (e.g. "for building access")
                <li> <tt>condition</tt>: any optional condition on the
                action performed (e.g. "if the student is not authorized")
              </ul>
            </p><br /> 
            <p>
              Each sentence corresponds to a <i>single</i> policy. 
              The constituents between '[' and ']' are optional; therefore, an
              input sentence must consist of, at minimum, 
              a subject, an action, and
              an object. Also, '*' means "one or more";
              thus, a policy may consist of any number of
              conditions.
            </p><br />
            <p>
              For example, the following sentence is a
              valid input policy to the Policy Parser:
            </p><br />
            <p>
              <b>Committee on Discipline may access prox card data
              for criminal investigation. </b>
            </p><br />
            <p>
              where:
              <ul id="panel">
                <li> the subject is <b>"Committee on Discipline"</b>;
                <li> the modality is the auxiliary verb <b>"may"</b>;
                <li> the object is <b>"prox card data"</b>;
                <li> the purpose is <b>"criminal investigation"</b>; and
                <li> the secondary object and the condition are none.
              </ul>
            </p><br />             
            <p><b>NTLK Parser</b>:</p><br />
            <p> Given a user's input policy, 
              the first step is to parse this sentence into a
              structured format that is manipulable by a
              computer. We use a <i>feature-based</i> context-free grammar
              (FCFG). Unlike an ordinary CFG, a FCFG embellishes 
              its production rules with extra attributes to denote
              each tree node having a set of properties. For example,
              the above sentence "Committee on Discipline may access
              prox card data for criminal investigation" is parsed
              into the following syntax tree: 
            </p><br />
            <p>
              (A syntax tree goes here)
            </p><br />
            <p>
              As shown in this tree, the left-hand side of 
              the top-level production rule 'S' contains a
              feature for each of the constituents (e.g. for example, 
              the feature "action" for the action constituent in the
              policy). The value assigned to each top-level feature 
              is defined in terms of features from the subtrees. Note
              that the l.h.s. of each part-of-speech rule 
              (e.g. 'NP' for noun-phrase) is augmented with the 'sem'
              feature; this allows us to assign a logical expression
              to each node in the tree. Here, we use the application
              of the lambda function 'cat' to concatenate one or more lexicons
              into a single constituent.  
            </p><br />
            <p>
              There are two benefits to this feauture-based
              approach over an ordinary CFG-based appraoch.  
              First of all, by explicitly stating each
              constituent as a top-level feature, it makes the process
              of extracting semantic information from a policy a lot
              eaiser; the Policy Interpreter (the next component in
              the pipeline) simply needs to walk over
              the list of top-level features and map each to a
              corresponding RDF construct. Secondly, the
              feature-based approach simplifies the grammar
              itself. For example, two sentences may be textually 
              different from each other but semantically, they may represent 
              the same policy. A FCFG that parses both of these
              sentences is smaller than
              a corresponding ordinary CFG, since the semantic
              information captured in the features allow us to
              collapse multiple production rules in the CFG into a single
              rule in the FCFG.
            </p><br />
            <p>  
              We used an existing infrastructure in the Natural
              Language Toolkit (NLTK) [1] for this part of the Policy
              Parser.  More specifcially, we adopted the data
              structure for FCFGs and the feature parser, both of
              which were available in a NLTK-based library [2], developed
              by Rob Speer.
              In addition to a user's sentence, 
              the FCFG parser in NLTK requires three arguments; the
              FCFG grammar (stored as a .fcfg file), the spelling
              change rules (a Kimmo file), and the
              lexicon (.lex file). All of these files are available in
              the <a href="download.html">Download Code</a> section. 
            </p><br />
            <p><b>Policy Interpreter</b>:</p><br />
            <p> Given a syntax tree generated by the NLTK Parser, the
              role of the Policy Interpreter is to extract the
              semantic information about the user's policy - i.e. the
              value for each of the constituents in the policy.  As
              mentioned above, this process is relatively
              straightforward, as it simply involves looking through 
              the list of features that are stored in the root of the syntax
              tree. The only intricate step in this process is walking
              over a lambda-calculus expression that is a
              concatentation of multiple lexical tokens (e.g. '(cat
              prox (cat card data))' for "prox card data"); this step is
              implemented using a recursive function for traversing an
              expression. 
            </p><br />
            <p>
              The output from the Policy Interpreter is a dictionary
              (i.e. a list of key-value pairs) that maps each
              constituent to its value.  For example, given the syntax
              tree for the sentence "Committee on Discipline may access
              prox card data for criminal investigation", the Policy
              Interpreter outputs the following dictionary: 
             </p><br />
			  <table border="0">
			    <tr>
                  <th align="left">Key</th>
                  <th align="left">Value</th>
                  <th align="left"></th>             
                </tr>
                <tr>
                  <td><tt>'POLICY'</tt></td>
                  <td><tt>'MIT Prox Card Policy'</tt></td>
                  <td>/* name of the policy */</td>
                </tr>
                  <td><tt>'ENTITY'</tt></td>
                  <td><tt>'Committee on Discipline'&nbsp&nbsp</td>
                  <td>/* actor */</td>
                <tr>
                  <td><tt>'FLAG'</tt></td>
                  <td>True</td>
                  <td>/* modality (True for positive, such as 'can') */</td>
                </tr>
                <tr>
                  <td><tt>'ACTION'</tt></td>
                  <td><tt>'use'</tt></td>
                  <td></td>
                </tr>
                <tr>
                  <td><tt>'PURPOSE'</tt></td>
                  <td><tt>'investigate crime'</tt></td>
                  <td></td>
                </tr>
                <tr>
                  <td><tt>'DATA'</tt></td>
                  <td><tt>'prox card data'</tt></td>
                  <td>/* object */</td>
                </tr>
                <tr>
                  <td><tt>'CONDITION'</tt></td>
                  <td>[ ]</td>
                  <td></td>
                </tr>
                <tr>
                  <td><tt>'SECONDARY ENTITY'&nbsp&nbsp</td>
                  <td>None</td>
                  <td></td>
                </tr>
              </table>
              <br /> 
              Note that some of the keys in the dictionary have
              different names than the constituents, but there is a 1-1 
              correspondence between these two sets of names.  The
              renaming was done due to the fact that RDF uses a set of
              pre-designated identifiers for its constructs. 
            </p><br />   
            <p>
              The Policy Interpreter has been implemented in Python and
              can be found in the PolicyInterpreter directory of the
              <a href="download.html">downloadble code</a>. 
            </p><br />
              <!-- RDF Generator -->
            
            <p><b>RDF Generator</b>:</p>
           <br/>
            
            <p>This module is responsible for generating
              <a href="http://dig.csail.mit.edu/TAMI/2007/AIR/">AIR
                (Accountability In RDF)</a> [4] policies. 
              Once the user's sentence is
              fragmented into the relevant constituents as described
              above, it will identify the corresponding RDF 
              segments and create the RDF graph using the
             <a href="http://rdflib.net/">RDFLib</a> [3] Python library. 
            </p>
            <br/>
            
            <p><a href="http://dig.csail.mit.edu/TAMI/2007/AIR/">AIR</a> 
              is a rule-based policy language written in 
              <a href="http://www.w3.org/RDF/">RDF</a> 
              for accountability and access control. Each AIR policy 
              consists of one or more rules:</p>
            <br /><pre>policy = { rule* } </pre><br />
	        <p>Each rule is made up of a pattern that when matched 
              causes an <code>action</code> to be fired. Optionally 
              there could be <code>description</code> and 
              <code>justification</code> 
            elements as well.</p>
            <br /><pre>rule = { pattern, action [ description justification ] } </pre><br />   
            <p> An <code>action</code> can either be an <code>assertion</code> (which is a set of facts  that are added to the knowledge base) or a nested <code>rule</code>.
            </p>
            <br /> <pre>action = { assertion | rule } </pre> <br />
            <p>The basic skeleton of an AIR policy is as follows:</p>
            <br/>
            <pre>
:MyFirstPolicy a air:Policy;
air:rule [
	air:variable { ... };
	air:pattern { ... };
	air:assertion { ... };
	air:rule [ ... ]
	].
	 		</pre>
            
            <p>In order to generate an AIR policy from a constrained
            natural language sentence, two additional parameters,
            besides the policy itself, are required:</p><br />
            <p>
            <ol id="panel">
            <li>Name for the policy</li>
            <li>One or more domain ontologies</li>
            </ol></p><br />
            
            <p>The name of the policy is required because the user
              should be able to identify the policy, and it is not 
              suitable to have a random machine-generated 
              policy name. The domain ontology is required because 
              some of the sentence fragments need to be identified 
              with the corresponding term (which could be 
              either a subject or a predicate or an object) in RDF.
            </p><br/>
            
            <p>The following diagram shows how the dictionary keys and values from the Policy Interpreter is used in constructing the AIR policy.</p>
            <br/>
            <div style="text-align: center;">
            <img src="images/rdf_gen.png" width=80% height=80% alt="RDF Generation"/>
             <p>Figure: Mapping from the sentence fragments to the AIR Policy</p><br/>
            </div>

            <p>The dictionary element 'POLICY' is used to name 
              the policy. If the keys of dictionary elements:
              'ENTITY', 
              'ACTION', 'PURPOSE', 'DATA' and 'PASSIVE ENTITY'
              have non-null values, they are used to assign 
              <code>air:variable</code>s. The values of these
              dictionary
              elements are then mapped on to <code>air:pattern</code>s
              where each <code>air:variable</code>s in the previous 
              step are assigned the corresponding <code>rdf:type</code>s. 
            </p>
            <br/>
            <p>The sentence could include conditions 
             as in the following sentence: "Committee on
             Discipline can use prox card data if the Committee 
                on Discipline has authorization". 
            The conditional phrase beginning with the word "if" may refer to components which are already identified, such as "Committee on Discipline" 
            (identified as the 'ENTITY'). Therefore another 
            pattern will be constructed with the subject, predicate or object values encoded in the 'CONDITION'. </p><br/>
            
                <p>All of these steps requires proper identification
              of the RDF terms as defined in the ontology. <a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL</a> queries are used to identify the correct 
              term from the RDF ontolgy. There is an underlying assumption that for each <code>rdfs:Class</code> and <code>rdfs:Property</code>, which corresponds to 
              subject/object and predicate respectively,  the ontology author has 
              defined a proper <code>rdfs:label</code> attribute. This attribute is very much likely to be used by the policy author, hence the SPARQL query
              is to search for the subject which matches the dictionary value. </p><br/> 
            <p>Finally, the 'FLAG' sent by the Policy 
              Interpreter will determine to specify whether 'ACTION'
              is compliant or not with the policy.</p><br/>
                        
            <!-- End of RDF Generator -->
            
            <p>
             [1] Steve Bird and Edward Loper. NLTK: The Natural
             Language Toolkit. <i>Proceedings of the ACL demonstration
             session</i>. pp 214-217, Barcelona, Association for
             Computational Lingusitics, July 2004. <br />
             [2] Rob Speer. The 6.863 Feature Parsing Library. 
             <a href="http://web.mit.edu/6.863/www/parser">
               http://web.mit.edu/6.863/www/parser</a>

               <!-- References for the RDF Generator -->
			<br/>               
             [3] RDFLib <a href="http://rdflib.net/">http://rdflib.net/</a><br />
             [4] Lalana Kagal, Chris Hanson, Daniel Weitzner at al, Decentralized Information Group, CSAIL, MIT. 
             AIR Policy Language <a href="http://dig.csail.mit.edu/TAMI/2007/AIR/">http://dig.csail.mit.edu/TAMI/2007/AIR/</a><br />
            <!-- End of References for the RDF Generator -->
               

            </p>

	    </div>
		
		<!-- End Content -->
		
		<!-- Start Footer -->
		
		<div id="footer">
			<p>&copy; 2008 Kasture Ltd. All right Reserved.</p>
		</div>
		
		<!-- End Footer -->
		 
    </div>
	
    <!-- End Wrapper -->
	
</body>
</html>
